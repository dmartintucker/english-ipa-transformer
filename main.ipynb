{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import re, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Globals\n",
    "DATA_PATH = 'data/'\n",
    "MODEL_PATH = 'models/'\n",
    "\n",
    "# Read data from source\n",
    "d = pd.read_csv(DATA_PATH+'english_US_ipa.csv.gz', compression='gzip') \\\n",
    "    .sample(frac=1.0)\n",
    "# d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\"\"\"\n",
    "First order of business is to choose the first of any records that have multiple IPA transcriptions\n",
    "e.g. /first/, /second/\n",
    "Second preprocessing step is to remove the wrapping transcription symbols '/','/'\n",
    "\"\"\"\n",
    "\n",
    "def preprocess_ipa_string(ipa):\n",
    "\n",
    "    try:\n",
    "        if ',' in ipa:\n",
    "            ipa = ipa.split(', ')[0]\n",
    "        reformatted_ipa = ipa.strip('/')\n",
    "\n",
    "    except:\n",
    "        reformatted_ipa = np.nan\n",
    "\n",
    "    finally:\n",
    "        return reformatted_ipa\n",
    "\n",
    "d['formatted_ipa'] = d['ipa'].apply(preprocess_ipa_string)\n",
    "d = d.drop(['ipa'], axis=1).dropna()\n",
    "# d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and vocabulary\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# \n",
    "inputs = d['english'].values\n",
    "outputs = d['formatted_ipa'].values\n",
    "\n",
    "# Initialize token sets\n",
    "input_tokens = set()\n",
    "output_tokens = set()\n",
    "\n",
    "# Iterate through dataframe\n",
    "for i in range(len(d)):\n",
    "    for token in list(d.iloc[i,0]):\n",
    "        input_tokens.add(token)\n",
    "    for token in list(d.iloc[i,1]):\n",
    "        output_tokens.add(token)\n",
    "\n",
    "input_tokens = sorted(list(input_tokens))\n",
    "output_tokens = sorted(list(output_tokens))\n",
    "\n",
    "# Dimensions\n",
    "encoder_token_dim = len(input_tokens)\n",
    "decoder_token_dim = len(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features_dict = dict([(token,i) for i, token in enumerate(input_tokens)])\n",
    "output_features_dict = dict([(token,i) for i, token in enumerate(output_tokens)])\n",
    "\n",
    "rev_input_features_dict = dict([(i,token) for token, i in enumerate(input_tokens)])\n",
    "rev_output_features_dict = dict([(i,token) for token, i in enumerate(output_tokens)])\n",
    "\n",
    "max_encoder_seq_len = max([len(i) for i in inputs])\n",
    "max_decoder_seq_len = max([len(i) for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = np.zeros(\n",
    "    ( len(inputs), max_encoder_seq_len, encoder_token_dim ), dtype='float32')\n",
    "decoder_inputs = np.zeros(\n",
    "    ( len(inputs), max_decoder_seq_len, decoder_token_dim ), dtype='float32')\n",
    "decoder_outputs = np.zeros(\n",
    "    ( len(outputs), max_decoder_seq_len, decoder_token_dim ), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, outputs) in enumerate(zip(inputs, outputs)):\n",
    "\n",
    "    for timestep, token in enumerate(list(inputs)):\n",
    "        encoder_inputs[i, timestep, input_features_dict[token]] = 1.\n",
    "    \n",
    "    for timestep, token in enumerate(outputs):\n",
    "        decoder_inputs[i, timestep, output_features_dict[token]] = 1.\n",
    "\n",
    "        if timestep > 0:\n",
    "            decoder_outputs[i, timestep-1, output_features_dict[token]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "n_dims = 64\n",
    "batch_size = 32\n",
    "n_epochs = 5\n",
    "\n",
    "# Model config\n",
    "# Encoder config\n",
    "model_encoder_inputs = Input(shape=(None, encoder_token_dim))\n",
    "model_encoder_lstm = LSTM(n_dims, return_state=True)\n",
    "model_encoder_outputs, hidden_state, state_cell = model_encoder_lstm(model_encoder_inputs)\n",
    "model_encoder_states = [hidden_state, state_cell]\n",
    "\n",
    "# Decoder config\n",
    "model_decoder_inputs = Input(shape=(None, decoder_token_dim))\n",
    "model_decoder_lstm = LSTM(n_dims, return_state=True, return_sequences=True)\n",
    "model_decoder_outputs, decoder_hidden_state, decoder_state_cell = model_decoder_lstm(model_decoder_inputs, initial_state=model_encoder_states)\n",
    "model_decoder_dense = Dense(decoder_token_dim, activation='softmax')\n",
    "model_decoder_outputs = model_decoder_dense(model_decoder_outputs)\n",
    "\n",
    "# Model compilation\n",
    "model = Model([model_encoder_inputs, model_decoder_inputs], model_decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3149/3149 [==============================] - 175s 54ms/step - loss: 0.6611 - accuracy: 0.0338 - val_loss: 0.6142 - val_accuracy: 0.0450\n",
      "Epoch 2/5\n",
      "3149/3149 [==============================] - 182s 58ms/step - loss: 0.5954 - accuracy: 0.0518 - val_loss: 0.5723 - val_accuracy: 0.0580\n",
      "Epoch 3/5\n",
      "3149/3149 [==============================] - 190s 60ms/step - loss: 0.5547 - accuracy: 0.0647 - val_loss: 0.5439 - val_accuracy: 0.0683\n",
      "Epoch 4/5\n",
      "3149/3149 [==============================] - 183s 58ms/step - loss: 0.5287 - accuracy: 0.0729 - val_loss: 0.5007 - val_accuracy: 0.0785\n",
      "Epoch 5/5\n",
      "3149/3149 [==============================] - 190s 60ms/step - loss: 0.5112 - accuracy: 0.0774 - val_loss: 0.4909 - val_accuracy: 0.0818\n"
     ]
    }
   ],
   "source": [
    "# Run training iterations\n",
    "history = model.fit([encoder_inputs, decoder_inputs], \n",
    "    decoder_outputs, \n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epochs,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "170718006dfac81896360e8a257dc24efb462d19d412097c1f4361fb23f709f9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('english-ipa-transformer-qcR_aUKM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
